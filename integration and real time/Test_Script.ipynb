{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GP Object Detection {Casting Product}\n",
    "# DEFECTO SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqzuKJqbUCX2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rgVQxR3UjBW"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXYtsiPVUooF"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGyVkhNNUssf"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vVV2eywXJ2t"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'Good', 'id':1},{'name':'Defected', 'id':2}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUTguPTdZfy6"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtzEqmBXxqax",
    "outputId": "4ae14124-3393-480d-b02d-2f1cdd189407"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAH8K2JIVKwT"
   },
   "source": [
    "# Load previous model if there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rt-eXLFPXSai"
   },
   "source": [
    "# Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3PZornvyllB"
   },
   "outputs": [],
   "source": [
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -v opencv-python==4.7.0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFKOiuUcDrDE"
   },
   "source": [
    "Importing cv and Libraries to show pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oa6kfDpu1Nee"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4qK8gow1SfO"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAH8K2JIVKwT"
   },
   "source": [
    "# Define classification model & function to classify given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import sys\n",
    "#sys.path.insert(0, 'C:\\\\object detection at4\\\\env3\\\\Lib\\\\site-packages')\n",
    "\n",
    "saved_model = tf.keras.models.load_model(\"model_vgg.h5\", compile=False)\n",
    "def classify(image1):\n",
    "    img = np.array(image1) / 255.0\n",
    "    img = img.reshape((1, 224, 224, 3))\n",
    "    #img = image1\n",
    "    #img = np.asarray(img)\n",
    "    #img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    output = saved_model.predict(img)\n",
    "    #print(output[0][0])\n",
    "    #print(output[0][1])\n",
    "    if output[0][0] > output[0][1]:\n",
    "        return 'defected'\n",
    "    else:\n",
    "        return 'good'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAH8K2JIVKwT"
   },
   "source": [
    "# Test classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "img = keras.utils.load_img(\"test images/ok2.jpeg\",target_size=(224,224))\n",
    "img = np.asarray(img)\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_test=cv2.imread('test images/ok2.jpeg')\n",
    "resized_image = cv2.resize(image_to_test, (224,224), interpolation = cv2.INTER_AREA)\n",
    "classify(resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAH8K2JIVKwT"
   },
   "source": [
    "# Test object detection then classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHdVFx5dC-vI"
   },
   "source": [
    "## define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    image_np = np.array(img)\n",
    "\n",
    "    #resize once for model to classify\n",
    "\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    print(num_detections)\n",
    "\n",
    "    calssify_result='none';\n",
    "    if(num_detections>=1):\n",
    "        resized_image = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n",
    "        calssify_result=classify(resized_image)\n",
    "\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    if (calssify_result=='good'):\n",
    "        label_id_offset=1\n",
    "    else:\n",
    "        label_id_offset=2\n",
    "\n",
    "\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "    result=detections['detection_classes'] + label_id_offset\n",
    "    plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHdVFx5dC-vI"
   },
   "source": [
    "## Test with image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image('test images/ok2.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAH8K2JIVKwT"
   },
   "source": [
    "# Real-time detection & classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAH8K2JIVKwT"
   },
   "source": [
    "# Demo with boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "num_good = 0\n",
    "num_defected = 0\n",
    "box_color=(255,255,255)\n",
    "\n",
    "capture_interval = 2  # Interval in seconds\n",
    "prev_capture_time = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    image_np = np.array(frame)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    # Filter detections based on confidence threshold\n",
    "    confidence_threshold = 0.97\n",
    "    boxes = detections['detection_boxes']\n",
    "    scores = detections['detection_scores']\n",
    "    filtered_indices = np.where(scores >= confidence_threshold)[0]\n",
    "    filtered_boxes = boxes[filtered_indices]\n",
    "\n",
    "    # Get the coordinates of the filtered detection boxes\n",
    "    height, width, _ = image_np_with_detections.shape\n",
    "    \n",
    "    \n",
    "    current_time = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "    elapsed_time = current_time - prev_capture_time\n",
    "\n",
    "    for box in filtered_boxes:\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        left = int(xmin * width)\n",
    "        right = int(xmax * width)\n",
    "        top = int(ymin * height)\n",
    "        bottom = int(ymax * height)\n",
    "        cropped_img = image_np[top:bottom,left:right] \n",
    "        #plt.imshow(cropped_img)\n",
    "        #plt.show()\n",
    "        result=\"CastingProduct\"\n",
    "\n",
    "        # Draw the borders with coordinates\n",
    "        #cv2.rectangle(image_np_with_detections, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        #cv2.putText(image_np_with_detections,result, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n",
    "        #           (0, 255, 0), 2)\n",
    "        \n",
    "        if ( elapsed_time > capture_interval):\n",
    "            classify_result = 'none'\n",
    "            #label_id_offset = 8\n",
    "\n",
    "            if num_detections >= 1:\n",
    "                resized_image = cv2.resize(cropped_img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "                classify_result = classify(resized_image)\n",
    "\n",
    "            if classify_result == 'good':\n",
    "                result=\"Good\"\n",
    "                box_color=(0, 255, 0)\n",
    "                num_good += 1\n",
    "\n",
    "            elif classify_result == 'defected':\n",
    "                box_color=(0, 0, 255)\n",
    "                result=\"Defected\"\n",
    "                num_defected += 1\n",
    "\n",
    "\n",
    "\n",
    "            prev_capture_time = current_time\n",
    "            cv2.rectangle(image_np_with_detections, (left, top), (right, bottom), box_color, 2)\n",
    "            cv2.putText(image_np_with_detections,result, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,box_color, 2)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            cv2.rectangle(image_np_with_detections, (left, top), (right, bottom), (255,255,255), 2)\n",
    "            cv2.putText(image_np_with_detections,result, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,box_color, 2)\n",
    "            \n",
    "\n",
    "    cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"Number of 'good' products:\", num_good)\n",
    "print(\"Number of 'defected' products:\", num_defected)        \n",
    "\n",
    "\n",
    "\n",
    "# Open file in write mode\n",
    "file_path = \"statistics.txt\"\n",
    "with open(file_path, \"a\") as file:\n",
    "    # Write variables to file\n",
    "    file.write(f\"Good products: {num_good}\\n\")\n",
    "    file.write(f\"defected products: {num_defected}\\n\")\n",
    "    file.write(f\"-----------end session-----------\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With DEFECTO System GUI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after install tkinter\n",
    "import tkinter as tk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Function to start the session\n",
    "def start_session():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    num_good = 0\n",
    "    num_defected = 0\n",
    "    box_color=(255,255,255)\n",
    "\n",
    "    capture_interval = 2  # Interval in seconds\n",
    "    prev_capture_time = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image_np = np.array(frame)\n",
    "\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "        detections = detect_fn(input_tensor)\n",
    "\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                      for key, value in detections.items()}\n",
    "        detections['num_detections'] = num_detections\n",
    "\n",
    "        # detection_classes should be ints.\n",
    "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "        label_id_offset = 1\n",
    "        image_np_with_detections = image_np.copy()\n",
    "\n",
    "        # Filter detections based on confidence threshold\n",
    "        confidence_threshold = 0.97\n",
    "        boxes = detections['detection_boxes']\n",
    "        scores = detections['detection_scores']\n",
    "        filtered_indices = np.where(scores >= confidence_threshold)[0]\n",
    "        filtered_boxes = boxes[filtered_indices]\n",
    "\n",
    "        # Get the coordinates of the filtered detection boxes\n",
    "        height, width, _ = image_np_with_detections.shape\n",
    "\n",
    "\n",
    "        current_time = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "        elapsed_time = current_time - prev_capture_time\n",
    "\n",
    "        for box in filtered_boxes:\n",
    "            ymin, xmin, ymax, xmax = box\n",
    "            left = int(xmin * width)\n",
    "            right = int(xmax * width)\n",
    "            top = int(ymin * height)\n",
    "            bottom = int(ymax * height)\n",
    "            cropped_img = image_np[top:bottom,left:right] \n",
    "            #plt.imshow(cropped_img)\n",
    "            #plt.show()\n",
    "            result=\"CastingProduct\"\n",
    "\n",
    "            # Draw the borders with coordinates\n",
    "            #cv2.rectangle(image_np_with_detections, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            #cv2.putText(image_np_with_detections,result, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n",
    "            #           (0, 255, 0), 2)\n",
    "\n",
    "            if ( elapsed_time > capture_interval):\n",
    "                classify_result = 'none'\n",
    "                #label_id_offset = 8\n",
    "\n",
    "                if num_detections >= 1:\n",
    "                    resized_image = cv2.resize(cropped_img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "                    classify_result = classify(resized_image)\n",
    "\n",
    "                if classify_result == 'good':\n",
    "                    result=\"Good\"\n",
    "                    box_color=(0, 255, 0)\n",
    "                    num_good += 1\n",
    "\n",
    "                elif classify_result == 'defected':\n",
    "                    box_color=(0, 0, 255)\n",
    "                    result=\"Defected\"\n",
    "                    num_defected += 1\n",
    "\n",
    "\n",
    "\n",
    "                prev_capture_time = current_time\n",
    "                cv2.rectangle(image_np_with_detections, (left, top), (right, bottom), box_color, 2)\n",
    "                cv2.putText(image_np_with_detections,result, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,box_color, 2)\n",
    "\n",
    "\n",
    "            else:\n",
    "                cv2.rectangle(image_np_with_detections, (left, top), (right, bottom), (255,255,255), 2)\n",
    "                cv2.putText(image_np_with_detections,result, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,box_color, 2)\n",
    "\n",
    "\n",
    "        cv2.imshow('object detection', cv2.resize(image_np_with_detections, (800, 600)))\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        good_label.config(text=\"Number of 'good' products: \" + str(num_good))\n",
    "        defected_label.config(text=\"Number of 'defected' products: \" + str(num_defected)) \n",
    "        \n",
    "    # Open file in write mode\n",
    "    file_path = \"statistics.txt\"\n",
    "    with open(file_path, \"a\") as file:\n",
    "    # Write variables to file\n",
    "    file.write(f\"Good products: {num_good}\\n\")\n",
    "    file.write(f\"defected products: {num_defected}\\n\")\n",
    "    file.write(f\"-----------end session-----------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Tkinter window\n",
    "import tkinter as tk\n",
    "window = tk.Tk()\n",
    "window.title(\"DEFECTO\")\n",
    "\n",
    "\n",
    "# Set window size and position it in the center of the screen\n",
    "window.geometry(\"500x700\")\n",
    "window.eval('tk::PlaceWindow . center')\n",
    "\n",
    "window.configure(bg=\"white\")\n",
    "\n",
    "# Create a label with the title \"DEFECTO\" centered\n",
    "title_label = tk.Label(window, text=\"DEFECTO\", font=(\"Helvetica\", 24))\n",
    "title_label.pack(pady=20)\n",
    "\n",
    "# Create a label with a lower font size for the description\n",
    "description_label = tk.Label(window, text=\"AI Defects Detection System\", font=(\"Helvetica\", 12))\n",
    "description_label.pack()\n",
    "\n",
    "# Create a logo image for your project (replace \"logo.png\" with the actual path to your logo image)\n",
    "logo_path = \"logo.png\"\n",
    "logo_image = tk.PhotoImage(file=logo_path)\n",
    "logo_label = tk.Label(window, image=logo_image)\n",
    "logo_label.pack(pady=10)\n",
    "\n",
    "# Create labels to display the counts\n",
    "good_label = tk.Label(window, text=\"Number of 'good' products: 0\")\n",
    "good_label.pack()\n",
    "\n",
    "defected_label = tk.Label(window, text=\"Number of 'defected' products: 0\")\n",
    "defected_label.pack()\n",
    "\n",
    "# Create the Start Session button\n",
    "start_button = tk.Button(window, text=\"Start Session\", command=start_session, bg=\"green\")\n",
    "start_button.pack()\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
